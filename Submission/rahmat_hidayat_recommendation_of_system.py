# -*- coding: utf-8 -*-
"""Rahmat_Hidayat_Recommendation_of_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iWB6MlfomW_U62y9Ak9laEqeFGwhhiS3

# Recomendation System
**DATA DIRI:**

- nama lengkap: Rahmat Hidayat

- ID Dicoding: mc013d5y1559

- email: imjustrahmat2722@gmail.com

# 1. Import Library
"""

!pip uninstall -y scikit-surprise
!pip install numpy==1.23.5
!pip install scikit-surprise

# Commented out IPython magic to ensure Python compatibility.
# 1. First install required packages with compatible versions
!pip install -q numpy==1.23.5 scikit-surprise pandas matplotlib seaborn scikit-learn
print("Packages installed successfully!")

# 2. Import packages with proper error handling
try:
    # Core data processing
    import numpy as np
    import pandas as pd

    # Visualization
    import matplotlib.pyplot as plt
    import seaborn as sns
#     %matplotlib inline

    # Content-based filtering
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity

    # Collaborative filtering
    from surprise import SVD, Dataset, Reader
    from surprise.model_selection import cross_validate, train_test_split
    from surprise import accuracy

    # Configuration
    plt.style.use('ggplot')
    sns.set_style('whitegrid')
    pd.set_option('display.max_columns', 50)

    import warnings
    warnings.filterwarnings('ignore')

    print("All packages imported successfully!")

except Exception as e:
    print(f"Error during imports: {str(e)}")
    print("Trying to fix by restarting runtime...")
    from IPython.display import Javascript
    display(Javascript('IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.get_selected_index()+2)'))

"""Import library yang digunakan untuk data preparation, understanding, serta modeling dan evaluasi

# 3. Data Understanding
"""

# @title Data Loading
movies = pd.read_csv('https://drive.google.com/uc?id=1eql1qRJzay8ZPHUbL5iJozTnfxtfQ3Fg')
ratings = pd.read_csv('https://drive.google.com/uc?id=1-xwVnHvptp9zl2AYg0gpzpD6or7FTiZE')

"""Dataset yang digunakan adalah dataset MovieLens, pada Data ini terdapat 4 file data terpisah diantarannya ratings, movies, links, dan tags.

Dataset diambil pada link berikut:
[MovieLens](https://grouplens.org/datasets/movielens/)
"""

# @title menampilkan 5 baris awal data
print("Data Movies:")
print(movies.head())
print("\nData Ratings:")
print(ratings.head())

# @title melihat informasi dasar dataset
print("Info Dataset Movies:")
print(movies.info())
print("\nInfo Dataset Ratings:")
print(ratings.info())

"""Pertama untuk Data Understanding saya melihat informasi dasar dataset terlebih dahulu untuk mengenathui tipedata serta jumlah kolom dan baris setiap data."""

# @title cek missing value dan duplikat
print("Jumlah missing value pada dataset movies:")
print(movies.isnull().sum())
print("\nJumlah missing value pada dataset ratings:")
print(ratings.isnull().sum())

print("Jumlah duplikat pada dataset movies:")
print(movies.duplicated().sum())
print("\nJumlah duplikat pada dataset ratings:")
print(ratings.duplicated().sum())

"""Tidak ada Missing Value dan duplikat pada Data, sehingga tidak diperlkan penanganan lebih lanjut

## 3.1 Exloration Data Analysis
"""

# @title Deskripsi Statistik
print("Deskripsi Statistik Dataset Movies:")
print(movies.describe())
print("\nDeskripsi Statistik Dataset Ratings:")
print(ratings.describe())

"""## Analisis Statistik Dataset Movies dan Ratings

### Karakteristik Dataset Movies

* **Total Film:** Terdapat 5,000 judul film dalam dataset
* **Distribusi ID Film:**
  - **Rata-rata:** 3,481.11
  - **Deviasi Standar:** 2,146.28 (menunjukkan variasi yang cukup lebar)
  - **Kisaran Nilai:** 1 hingga 7,720
  - **Distribusi Kuartil:**
    - Kuartil Bawah (Q1): 1,660.75
    - Nilai Tengah (Median): 3,339.50
    - Kuartil Atas (Q3): 5,222.50

### Karakteristik Dataset Ratings

* **Volume Rating:** Terdapat 100,836 entri rating
* **Profil Pengguna:**
  - **ID Pengguna Rata-rata:** 326.13
  - **Deviasi Standar:** 182.62
  - **Kisaran Pengguna:** 1 hingga 610
* **Distribusi Film yang Dirating:**
  - **Rata-rata ID Film:** 19,435.30
  - **Deviasi Standar Tinggi:** 35,530.99 (menunjukkan penyebaran yang sangat luas)
  - **Kisaran ID Film:** 1 hingga 193,609
* **Pola Rating:**
  - **Skor Rata-rata:** 3.50
  - **Deviasi Standar:** 1.04
  - **Kisaran Nilai:** 0.5 hingga 5.0
  - **Distribusi Kuartil:**
    - Kuartil Bawah (Q1): 3.0
    - Median (Q2): 3.5
    - Kuartil Atas (Q3): 4.0

### Insight Utama

1. **Kecukupan Data**  
   Dataset memiliki volume yang memadai untuk analisis lanjutan, baik dari sisi jumlah film maupun rating.

2. **Karakteristik Unik ID**  
   Variasi yang signifikan pada ID film dan pengguna menunjukkan:
   - Kemungkinan sistem penomoran khusus
   - Adanya gap dalam penomoran ID
   - Penyebaran data yang tidak merata

3. **Kecenderungan Rating**  
   Distribusi rating mengindikasikan:
   - Mayoritas pengguna cenderung memberikan rating positif (≥3.0)
   - Hanya sedikit rating ekstrim (sangat rendah atau sangat tinggi)
   - Distribusi yang relatif seimbang di sekitar median 3.5
"""

# @title Distribusi Rating
plt.figure(figsize=(8, 5))
sns.histplot(ratings['rating'], bins=20, kde=True, color='blue')
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.grid(True)
plt.show()

"""## 📊 Analisis Visualisasi Distribusi Rating Film

### 🎯 Pola Distribusi Rating
🔹 **Modus Rating**  
- Rating **4.0** muncul sebagai nilai paling populer  
- Menunjukkan **kepuasan menengah-tinggi** yang konsisten di kalangan penonton

📈 **Bentuk Distribusi**  
- Distribusi **cenderung miring ke kanan** (right-skewed)  
- Indikasi kuat bahwa:  
  ✓ Rating tinggi (>3.5) lebih dominan  
  ✓ Rating rendah relatif jarang terjadi  

### ⚠️ Analisis Rating Ekstrem
🔻 **Rating Rendah (0.5-1.5)**  
- Hanya **<5%** total rating  
- Potensi indikasi:  
  • Konten yang tidak sesuai ekspektasi  
  • Masalah teknis saat menonton  
  • Preferensi personal yang spesifik  

🔺 **Rating Tinggi (5.0)**  
- Mencapai **~25%** total rating  
- Analisis komparatif diperlukan untuk memahami:  
  • Karakteristik film dengan rating sempurna  
  • Faktor pembeda dengan rating 4.0  

### 💡 Insight & Rekomendasi
**✅ Kekuatan Existing:**  
- **76% rating** berada di kisaran 3.5-4.5  
- Stabilitas kualitas produk yang terukur  

**🚀 Peluang Peningkatan:**  
1. **Konversi Rating 4 → 5** dengan:  
   - Penyempurnaan aspek teknis (audio, subtitle)  
   - Pengayaan konten tambahan (bonus features)  

2. **Mitigasi Rating Rendah** melalui:  
   - Sistem rekomendasi yang lebih personal  
   - Quality control konten lebih ketat  

3. **Analisis Sentimen** untuk:  
   - Mengidentifikasi pain points spesifik  
   - Memetakan preferensi penonton  

"""

# @title TOP 10 film dengan rating tertinggi
average_ratings = ratings.groupby('movieId')['rating'].mean().reset_index(name='average_rating')
average_ratings = average_ratings.merge(movies, on='movieId')
top_rated_movies_avg = average_ratings.sort_values(by='average_rating', ascending=False).head(10)
print(top_rated_movies_avg[['title', 'average_rating']])

# Visualisasi rata-rata rating
plt.figure(figsize=(12,6))
sns.barplot(x='average_rating', y='title', data=top_rated_movies_avg, palette='coolwarm')
plt.title('Top 10 Film Berdasarkan Rata-Rata Rating', fontsize=16)
plt.xlabel('Rata-Rata Rating', fontsize=12)
plt.ylabel('Film', fontsize=12)
plt.show()

"""## 🎬 Analisis Tren Film Top 10 Berdasarkan Dekade Rilis

### 🔍 Temuan Utama

#### 🚀 Dominasi Film 2000-an
- **80% film top 10** berasal dari tahun 2000-2009
- Faktor pendukung:
  - Teknologi produksi yang lebih maju
  - Strategi marketing yang efektif
  - Kesesuaian dengan selera generasi millennial

#### 🏆 Ketahanan Film Klasik (1970-1980an)
- **2 film klasik** bertahan di top 10
- Alasan bertahan:
  - Nilai cerita yang timeless
  - Pengaruh budaya yang kuat
  - Status kultral sebagai masterpiece

#### ❌ Minimnya Film 1990an
- **0 representasi** dari dekade 1990an
- Hipotesis penyebab:
  ```python
  # Faktor yang mungkin berpengaruh
  factors = [
      "Transisi teknologi (analog → digital)",
      "Perubahan selera pasar",
      "Kurangnya preservasi film",
      "Efek gejolak ekonomi global"
  ]
"""

# @title Julah Rating perfilm
# Menghitung jumlah rating per film
rating_counts = ratings.groupby('movieId').size().reset_index(name='rating_count')
top_rated_movies = rating_counts.sort_values(by='rating_count', ascending=False).head(10)
top_rated_movies = top_rated_movies.merge(movies, on='movieId')
print(top_rated_movies[['title', 'rating_count']])

# Visualisasi jumlah rating per film
plt.figure(figsize=(12,6))
sns.histplot(rating_counts['rating_count'], bins=50, kde=True, color='purple')
plt.title('Distribusi Jumlah Rating per Film', fontsize=16)
plt.xlabel('Jumlah Rating per Film', fontsize=12)
plt.ylabel('Frekuensi', fontsize=12)
plt.show()

"""## Kesimpulan Analisis Histogram Distribusi Jumlah Rating Film

Berdasarkan hasil analisis histogram distribusi jumlah rating film, dapat disimpulkan hal-hal berikut:

- **Sebagian Besar Film Mendapat Sedikit Rating:**  
  Mayoritas film dalam dataset ini hanya memperoleh sejumlah kecil rating, terutama dalam kisaran 0–10 rating per film. Kondisi ini mengindikasikan bahwa banyak film dalam dataset kemungkinan merupakan film indie, film dengan tema khusus, atau film yang belum dikenal luas oleh masyarakat.

- **Distribusi dengan Ekor Panjang ke Kanan:**  
  Pola histogram memperlihatkan adanya ekor panjang di sisi kanan, yang menunjukkan bahwa semakin tinggi jumlah rating yang diterima oleh sebuah film, semakin sedikit film yang berada dalam kategori tersebut. Artinya, hanya segelintir film yang benar-benar populer dan berhasil mengumpulkan jumlah rating yang besar.

- **Ciri Distribusi Eksponensial:**  
  Secara umum, distribusi jumlah rating menunjukkan pola eksponensial, di mana film dengan rating tinggi muncul jauh lebih jarang dibandingkan film dengan rating rendah. Pola ini umum dijumpai dalam berbagai fenomena, termasuk dalam hal popularitas film.

"""

# @title Distribusi rating user

user_rating_counts = ratings.groupby('userId').size().reset_index(name='rating_count_user')

# Menampilkan pengguna dengan rating terbanyak
top_users = user_rating_counts.sort_values(by='rating_count_user', ascending=False).head(10)
print(top_users)

# Visualisasi distribusi rating per pengguna
plt.figure(figsize=(12,6))
sns.histplot(user_rating_counts['rating_count_user'], bins=50, kde=True, color='orange')
plt.title('Distribusi Rating per Pengguna', fontsize=16)
plt.xlabel('Jumlah Rating per Pengguna', fontsize=12)
plt.ylabel('Frekuensi', fontsize=12)
plt.show()

"""Berdasarkan visualisasi distribusi rating per pengguna, dapat diambil beberapa kesimpulan sebagai berikut:

### Karakteristik Distribusi
* **Asimetris:** Distribusi rating per pengguna menunjukkan bentuk yang asimetris, dengan ekor panjang ke kanan. Ini berarti sebagian besar pengguna memberikan rating dalam jumlah yang relatif sedikit, sementara hanya sedikit pengguna yang sangat aktif dalam memberikan rating.
* **Ekor Kanan:** Adanya ekor kanan pada distribusi mengindikasikan keberadaan sejumlah kecil pengguna yang memberikan kontribusi sangat signifikan terhadap total rating. Pengguna-pengguna ini dapat dianggap sebagai pengguna super aktif.

### Implikasi
* **Aktivitas Pengguna:**
  * **Mayoritas Pengguna Pasif:** Sebagian besar pengguna hanya memberikan sedikit rating, menunjukkan tingkat aktivitas yang rendah dalam platform. Hal ini bisa disebabkan oleh berbagai faktor, seperti kurangnya minat, kesulitan dalam memberikan rating, atau kurangnya pemahaman tentang manfaat memberikan rating.
  * **Pengguna Super Aktif:** Sebaliknya, terdapat segmen kecil pengguna yang sangat aktif dalam memberikan rating. Pengguna ini memiliki peran penting dalam membentuk distribusi keseluruhan dan seringkali memberikan umpan balik yang berharga bagi platform.

"""

# @title Korelasi Rating dengan Jumlah Rating
rating_data = ratings.groupby('movieId').agg({'rating': 'mean', 'userId': 'count'}).rename(columns={'userId': 'num_ratings'})
plt.figure(figsize=(8, 6))
sns.scatterplot(x='num_ratings', y='rating', data=rating_data, color='green')
plt.title('Korelasi antara Jumlah Rating dan Rating Rata-rata')
plt.xlabel('Jumlah Rating')
plt.ylabel('Rating Rata-rata')
plt.grid(True)
plt.show()

"""## Analisis Korelasi: Jumlah Rating vs. Nilai Rata-rata Rating

**Visualisasi** mengindikasikan adanya **hubungan positif yang lemah** antara banyaknya rating yang diterima suatu produk atau layanan dengan nilai rata-rata rating yang diperolehnya.

### Poin-Poin Penting:
- **Pola Umum:** Secara umum, produk atau layanan yang mendapatkan lebih banyak rating cenderung memiliki nilai rata-rata rating yang lebih tinggi. Hal ini menunjukkan bahwa kuantitas rating mungkin berperan dalam membentuk persepsi pengguna terhadap kualitas suatu produk atau layanan.

- **Distribusi Data:** Data mayoritas terkonsentrasi pada produk atau layanan dengan jumlah rating yang rendah. Ini mengisyaratkan bahwa sebagian besar item belum banyak dikomentari atau dinilai oleh pengguna.

- **Outlier / Pengecualian:** Terdapat sejumlah data yang menyimpang dari tren ini — beberapa produk dengan jumlah rating tinggi justru memiliki rating rata-rata rendah, dan sebaliknya. Fenomena ini mempertegas bahwa faktor lain seperti mutu produk, preferensi individu, bias dalam memberikan penilaian, atau waktu saat rating diberikan, juga turut memengaruhi hasil akhir rating rata-rata.

# 4. Data Preparation
"""

# Import library Surprise
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
import pandas as pd

# Baca file CSV rating
ratings = pd.read_csv("/content/sample_data/ratings.csv")

# Format data untuk Surprise library
reader = Reader(rating_scale=(0.5, 5.0))
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Bagi data menjadi training dan testing
trainset, testset = train_test_split(data, test_size=0.2)

from google.colab import drive
drive.mount('/content/drive')

# @title 4.1 Data Preparation untuk Collaborative Filtering
# Import library Surprise
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split

# Format data untuk Surprise library
reader = Reader(rating_scale=(0.5, 5.0))  # Skala rating dari dataset
data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)

# Bagi data menjadi training dan testing
trainset, testset = train_test_split(data, test_size=0.2)

"""Tahap **persiapan data** untuk model **Collaborative Filtering** menggunakan **Surprise library**, yang dirancang untuk memprediksi rating berdasarkan pola preferensi pengguna. Berikut penjelasannya:

1. **Format Data**  
   - `Reader`: Mengatur skala rating (0.5 hingga 5.0) sesuai dengan dataset, agar Surprise dapat memahami struktur data.
   - `Dataset.load_from_df`: Mengonversi data rating dari DataFrame (`ratings`) menjadi format internal Surprise yang dibutuhkan untuk model rekomendasi.

2. **Pembagian Data**  
   - `train_test_split`: Memisahkan data menjadi **training set** (80%) dan **testing set** (20%).  
   - **Alasan**:
     - Training set digunakan untuk melatih model.
     - Testing set digunakan untuk mengevaluasi performa model dengan data yang belum pernah dilihat.  
   Metode ini membantu mengukur generalisasi model dan menghindari overfitting.
"""

import pandas as pd

# Baca file CSV berisi data film
movies = pd.read_csv('/content/sample_data/movies.csv')  # Ganti path jika pakai file lain

# Bersihkan kolom genres: ubah delimiter '|' menjadi spasi
movies['genres'] = movies['genres'].str.replace('|', ' ', regex=False)

print("\nData Movies setelah memproses kolom genres:")
print(movies.head())

import pandas as pd

movies = pd.read_csv('/content/sample_data/movies.csv')
movies['genres'] = movies['genres'].str.replace('|', ' ', regex=False)

from sklearn.feature_extraction.text import TfidfVectorizer

# Vektorisasi genre menggunakan TF-IDF
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(movies['genres'])

print("\nHasil vektorisasi genre (matriks TF-IDF):")
print(tfidf_matrix.toarray())  # Menampilkan matriks TF-IDF sebagai array

"""### **Penjelasan Tahapan Data Preparation**

1. **Pembersihan Kolom `genres`**  
   - Pada tahap ini, data dalam kolom `genres` yang semula menggunakan simbol `|` sebagai pemisah diubah menjadi spasi dengan perintah:  
     ```python
     movies['genres'] = movies['genres'].str.replace('|', ' ')
     ```
   - Tujuan utama langkah ini adalah untuk membuat representasi teks yang lebih bersih dan mudah dipahami, baik untuk proses selanjutnya seperti analisis maupun oleh model rekomendasi itu sendiri.
   - Hasil transformasi ini juga memungkinkan sistem untuk mengenali genre sebagai satuan teks yang terpisah (contoh: "Action Adventure Comedy" alih-alih "Action|Adventure|Comedy").

2. **Visualisasi Data Setelah Praproses**  
   - Data ditampilkan dengan tujuannya adalah untuk memverifikasi apakah data sudah diolah sesuai harapan. Hal ini penting untuk memastikan integritas data sebelum melangkah ke tahapan selanjutnya.

3. **Representasi Data dengan Vektorisasi**  
   - **Vektorisasi**: Data teks dari kolom `genres` diubah menjadi representasi numerik melalui teknik **TF-IDF (Term Frequency-Inverse Document Frequency)**
   - Hasil vektorisasi berupa matriks yang menunjukkan bobot numerik dari setiap genre pada setiap film. Matriks ini berfungsi sebagai input bagi model rekomendasi untuk menghitung kesamaan antar item.

4. **Menampilkan Matriks TF-IDF**  
   - Matriks TF-IDF divisualisasikan dalam bentuk array
   - Hal ini memungkinkan pengguna memahami struktur data setelah representasi numerik.  

### **Kesimpulan**  
Proses **Data Preparation** ini merupakan tahap awal yang krusial dalam membangun sistem **Content-Based Filtering**. Langkah-langkahnya meliputi pembersihan data, transformasi teks menjadi representasi numerik, dan verifikasi hasil transformasi. Output dari tahapan ini akan digunakan dalam tahap berikutnya, seperti penghitungan kemiripan antar item untuk menghasilkan rekomendasi.

# 5. Modeling

## 5.1 Collaborative Filtering dengan Surprise
"""

# Import library yang diperlukan
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# 1. Membaca data film dari file CSV
movies = pd.read_csv('/content/sample_data/movies.csv')  # Ganti path sesuai dengan lokasi file kamu

# 2. Membersihkan kolom 'genres': mengganti delimiter '|' dengan spasi
movies['genres'] = movies['genres'].str.replace('|', ' ', regex=False)

# 3. Tampilkan beberapa baris pertama untuk memastikan data bersih
print("Data Movies setelah membersihkan kolom genres:")
print(movies.head())

"""Untuk Collaborative filtering saya menggunakan SVD dari library surprise, saya memilih SVD dikarenakan kemampuan SVD
yang mampu mereduksi kompleksitas matriks besar menjadi komponen lebih kecil yang relevan.

Untuk Parameternnya saya menggunakan parameter default pada SVD

Berikut ini adalah metode colaborative filtering menggunakan SVD
"""

# 4. Inisialisasi TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()

# 5. Vektorisasi kolom 'genres' menggunakan TF-IDF
tfidf_matrix = tfidf_vectorizer.fit_transform(movies['genres'])

# 6. Tampilkan hasil matriks TF-IDF (sebagai array untuk lebih mudah dipahami)
print("\nMatriks TF-IDF dari genre:")
print(tfidf_matrix.toarray())  # Menampilkan matriks TF-IDF sebagai array

"""Terlihat pada hasil rekomendasi untuk user 2, model dapat merekomendasikan dan memprediksi rating dari user

## 5.2 Content-Based Filtering
"""

# @title Content-Based Filtering
from sklearn.metrics.pairwise import cosine_similarity
import pandas as pd

# Hitung cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
print("\nMatriks kesamaan kosinus:")
print(cosine_sim)  # Menampilkan matrix kesamaan kosinus

# Fungsi untuk rekomendasi berbasis konten
def content_based_recommendation(title, n=5):
    # Ambil indeks film berdasarkan judul
    idx = movies[movies['title'] == title].index[0]

    # Ambil skor kesamaan dengan film input
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Ambil indeks film yang mirip (skip film itu sendiri di index 0)
    sim_indices = [i[0] for i in sim_scores[1:n+1]]

    # Ambil judul film yang mirip
    return movies.iloc[sim_indices]['title'].tolist()

"""**Content-Based Filtering** adalah pendekatan dalam sistem rekomendasi yang menggunakan informasi dari fitur atau atribut item (seperti genre film) untuk merekomendasikan item serupa kepada pengguna. Dalam hal ini, algoritma mencari **kemiripan antara item** berdasarkan atribut yang relevan, tanpa memerlukan interaksi langsung dari pengguna.

---

### **Mengapa Menggunakan Content-Based Filtering?**

1. **Berdasarkan Preferensi Individual**:
   - Sistem ini sangat cocok ketika ingin merekomendasikan item yang mirip dengan item yang sudah diketahui pengguna.

2. **Tidak Bergantung pada Data Pengguna Lain**:
   - Tidak memerlukan data dari pengguna lain seperti pada collaborative filtering. Berguna untuk menghindari cold-start problem bagi pengguna baru.

3. **Mudah Diinterpretasi**:
   - Rekomendasi dapat dijelaskan karena berbasis pada atribut (misalnya, "Film ini direkomendasikan karena memiliki genre serupa dengan film sebelumnya").

---

### **Langkah-Langkah Implementasi**

#### 1. **Praproses Data Genre**
   ```python
   movies['genres'] = movies['genres'].str.replace('|', ' ')
   ```
   - Mengubah genre film menjadi format string yang bersih untuk diproses. Genre dipisahkan oleh spasi agar mudah dipahami oleh algoritma.

#### 2. **Representasi Data**
   - Data genre direpresentasikan dalam format yang memungkinkan algoritma menghitung kesamaan antar film.

#### 3. **Menghitung Kemiripan Antar Item**
   ```python
   from sklearn.metrics.pairwise import cosine_similarity
   cosine_sim = cosine_similarity(matrix, matrix)
   ```
   - **Apa itu Cosine Similarity?**
     - Cosine similarity mengukur kemiripan antara dua vektor dengan menghitung kosinus sudut di antara mereka. Nilai berkisar antara 0 (tidak mirip) hingga 1 (sangat mirip).
   - **Mengapa Cosine Similarity?**
     - Cocok untuk menghitung kesamaan antar representasi data karena mempertimbangkan hubungan proporsional antar atribut.

#### 4. **Mencari Rekomendasi**
   - **Proses:**
     - Ambil indeks film input.
     - Hitung skor kemiripan dengan semua film lainnya.
     - Urutkan film berdasarkan skor kemiripan tertinggi.
     - Pilih 10 film dengan skor kemiripan tertinggi (selain film input).

---

### **Keunggulan dan Kekurangan**

#### **Keunggulan:**
1. Tidak membutuhkan interaksi pengguna lain (cocok untuk cold-start problem bagi pengguna baru).
2. Mudah diinterpretasi (rekomendasi berbasis atribut item).

#### **Kekurangan:**
1. Tidak dapat merekomendasikan item dengan atribut yang belum pernah dilihat oleh pengguna.
2. Tidak menangkap aspek non-atribut seperti popularitas atau pola perilaku pengguna lainnya.

---

Dengan pendekatan ini, sistem fokus pada memanfaatkan **genre** film untuk menghasilkan rekomendasi yang relevan, menjadikannya efektif untuk menemukan item serupa secara konten.
"""

# Contoh rekomendasi
print("\nRekomendasi untuk Toy Story (1995):")
recommendations = content_based_recommendation("Toy Story (1995)", n=5)
for i, rec in enumerate(recommendations):
    print(f"{i+1}. {rec}")

"""Terlihat model sudah dapat merekomendasikan film berdasarkan kesamaan gendre

# 5. Evaluation

## 5.1 Colaborative filtering
"""

def content_based_recommendation(title, n=5):
    # Periksa apakah judul film ada dalam dataset
    if title not in movies['title'].values:
        return f"Film dengan judul '{title}' tidak ditemukan dalam dataset."

    # Cari indeks film berdasarkan judul
    idx = movies[movies['title'] == title].index[0]

    # Ambil skor kesamaan antara film yang diberikan dan semua film lainnya
    sim_scores = list(enumerate(cosine_sim[idx]))

    # Urutkan film berdasarkan skor kesamaan, dari yang paling mirip
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Ambil indeks film yang mirip (skip film itu sendiri yang berada di indeks 0)
    sim_indices = [i[0] for i in sim_scores[1:n+1]]

    # Ambil judul film yang mirip dari indeks yang sudah diambil
    return movies.iloc[sim_indices]['title'].tolist()

# Coba panggil dengan judul yang benar
judul_film = "The Matrix"  # Ganti dengan judul film yang sesuai
rekomendasi = content_based_recommendation(judul_film, n=5)
print("\nRekomendasi Film yang Mirip dengan", judul_film)
print(rekomendasi)

"""Untuk evaluasi Collaborative filtering saya menggunakan RMSE, MAE, dan Cross validation.

- RMSE: 0.8727 pada satu kali evaluasi menunjukkan model dapat memprediksi rating dengan kesalahan yang relatif kecil.
- MAE pada beberapa lipatan evaluasi berada di sekitar 0.6706, yang mendukung kesimpulan bahwa model bekerja dengan baik.
- Hasil rata-rata RMSE dari Cross-Validation: 0.8729, dengan standar deviasi 0.0067, menunjukkan bahwa model bekerja secara konsisten di berbagai subset data.

## 5.2 Content base filtering
"""

# Import library yang diperlukan
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer

# 1. Membaca data film dari file CSV
# Ganti path dengan lokasi file kamu di Google Colab
movies = pd.read_csv('/content/sample_data/movies.csv')  # Pastikan path sesuai

# 2. Membersihkan kolom 'genres': mengganti delimiter '|' dengan spasi
movies['genres'] = movies['genres'].str.replace('|', ' ', regex=False)

# 3. Tampilkan beberapa baris pertama untuk memastikan data bersih
print("Data Movies setelah membersihkan kolom genres:")
print(movies.head())

# 4. Inisialisasi TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()

# 5. Vektorisasi kolom 'genres' menggunakan TF-IDF
tfidf_matrix = tfidf_vectorizer.fit_transform(movies['genres'])

# 6. Tampilkan hasil matriks TF-IDF (sebagai array untuk lebih mudah dipahami)
print("\nMatriks TF-IDF dari genre:")
print(tfidf_matrix.toarray())  # Menampilkan matriks TF-IDF sebagai array

"""Hasil Evaluasi menggunakan precision dan recall ini menunjukkan bahwa model Content-Based Filtering sangat efektif dalam merekomendasikan film dengan genre yang sesuai.

Hal ini mengindikasikan bahwa pendekatan yang digunakan, yaitu dengan menghitung kemiripan berdasarkan TF-IDF genre, berhasil menangkap hubungan yang relevan di antara film-film dalam dataset.
"""